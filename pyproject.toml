[tool.poetry]
name = "embedding-model-fine-tuning"
version = "0.1.0"
description = "Project doing fine-tuning process on various embedding models including bge-m3, snowflake-arctic etc."
authors = ["WB-Jang"]
readme = "README.md"
packages = [{include = "src"}]

[tool.poetry.dependencies]
python = "^3.9"
pandas = "^2.0.0"
sentence-transformers = "^2.2.0"
# SentenceTransformers 내부에서도 transformers를 사용하지만,
# 명시적으로 버전을 관리하기 위해 별도로 추가합니다.
transformers = "^4.38.0"

# Hugging Face 기반 학습/추론 파이프라인 확장용(선택적이지만 유용)
accelerate = "^0.28.0"
datasets = "^2.18.0"

# API 서버용
fastapi = "^0.110.0"
uvicorn = {version = "^0.27.0", extras = ["standard"]}

# torch는 Docker 베이스 이미지(pytorch/pytorch:2.2.0-cuda12.1-cudnn8-runtime)에
# 이미 GPU+CUDA 버전으로 설치되어 있으므로 여기서는 명시하지 않습니다.
# 로컬(비도커) 환경에서 Poetry만 사용하는 경우에는 별도로 'pip install torch ...'가 필요할 수 있습니다.

[tool.poetry.group.dev.dependencies]
pytest = "^7.0.0"
black = "^23.0.0"
flake8 = "^6.0.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
